{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:08:57.399157900Z",
     "start_time": "2024-06-05T12:08:36.197148800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "file_path = 'D:/EDM/数据集相关/22级学生行为数据集/DataSet_V5_new_filled.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.drop(columns=['xh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba720b602bf5077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:33:16.126478300Z",
     "start_time": "2024-05-28T09:33:15.976691100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 进行方差选择法特征选择\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "df_new= selector.fit_transform(df)\n",
    "\n",
    "# 输出选择的特征\n",
    "print(\"原始特征数：\", df.shape[1])\n",
    "print(\"过滤后的特征数：\", df_new.shape[1])\n",
    "selected_features = df.columns[selector.get_support()]\n",
    "print(\"选择的特征：\", selected_features)\n",
    "# 将 df_new 转换为 DataFrame，并使用原始的列名\n",
    "df_new = pd.DataFrame(df_new, columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34f5b9d872e65cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:09:38.863693200Z",
     "start_time": "2024-06-05T12:09:38.694633300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_new.drop(columns=['label'])\n",
    "# X = df.drop(columns=['xh','label'])\n",
    "y = df_new['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, stratify=y, random_state=42)\n",
    "\n",
    "# 第二次划分，得到测试集 (20%) 和验证集 (10%)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.3, stratify=y_temp, random_state=42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df[df.columns[1:31]], df[\"label\"], train_size=0.8, stratify=df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300e4958cff82c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cde34213a5e6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:10:00.518981900Z",
     "start_time": "2024-06-05T12:09:58.469291700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成完毕\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, RandomOverSampler\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# 过滤警告信息\n",
    "warnings.filterwarnings(\"ignore\", message=\"Best weights from best epoch are automatically used!\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Detected call of `lr_scheduler.step()` before `optimizer.step()`\")\n",
    "sampling_strategy = {1:300, 2:300, 3:300,4:300}\n",
    "# sampling_strategy = {1:300, 2:300,3:300}\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy,k_neighbors=3)\n",
    "bsmote = BorderlineSMOTE(sampling_strategy=sampling_strategy,k_neighbors=3)\n",
    "svmsmote = SVMSMOTE(sampling_strategy=sampling_strategy,k_neighbors=3)\n",
    "# X_smote,y_smote=smote.fit_resample(X_train,y_train)\n",
    "X_smote,y_smote=bsmote.fit_resample(X_train,y_train)\n",
    "# X_smote,y_smote=svmsmote.fit_resample(X_train,y_train)\n",
    "print(\"数据生成完毕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60d131",
   "metadata": {},
   "source": [
    "定义FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e791010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "labels = df_new['label'].values\n",
    "\n",
    "# 计算类别权重\n",
    "classes = torch.unique(torch.tensor(labels))\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes.numpy(), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "# 定义TabNet模型\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction=self.reduction)(input, target)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(target.device)\n",
    "            pt = torch.exp(-ce_loss)\n",
    "            focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        else:\n",
    "            focal_loss = (1 - torch.exp(-ce_loss)) ** self.gamma * ce_loss\n",
    "\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1843c5e60cfc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "采用新数据训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d158b01014a4c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:49:02.834354300Z",
     "start_time": "2024-06-05T12:49:02.644699900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "tabnet_model = TabNetClassifier()\n",
    "tabnet_model.loss_fn=FocalLoss(gamma=2.0, alpha=class_weights, reduction='mean')\n",
    "# tabnet_model.loss_fn=FocalLoss(class_weights)\n",
    "\n",
    "# tabnet_model = TabNetClassifier()\n",
    "avg_accuracy =0\n",
    "tabnet_model.fit(\n",
    "    X_train=X_smote,\n",
    "    y_train=y_smote,\n",
    "    eval_set=[(X_val, y_val), (X_test, y_test)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100\n",
    ")\n",
    "\n",
    "    # 训练模型\n",
    "test_preds = tabnet_model.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "acc = accuracy_score(y_test, test_preds)\n",
    "avg_accuracy += acc\n",
    "result = confusion_matrix(y_test, test_preds)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(result)\n",
    "result1 = classification_report(y_test, test_preds)\n",
    "print(\"Classification Report:\", )\n",
    "print(result1)\n",
    "print(f\"Test accuracy score: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9801acc319f018",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "加入群优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d1d17f1dd8161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:26:51.816620600Z",
     "start_time": "2024-05-28T10:26:51.815544Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from mealpy import Problem, FloatVar, IntegerVar\n",
    "\n",
    "data = {\n",
    "    \"X_train\": X_smote,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_train\": y_smote,\n",
    "    \"y_test\": y_test,\n",
    "    \"X_val\":X_val,\n",
    "    \"y_val\":y_val\n",
    "}\n",
    "\n",
    "# 定义优化问题中的Problem\n",
    "class TabNetOptimizedProblem(Problem):\n",
    "    def __init__(self, bounds=None, minmax=\"max\", data=None, **kwargs):\n",
    "        self.data = data\n",
    "        super().__init__(bounds, minmax, **kwargs)\n",
    "\n",
    "    def obj_func(self, x):\n",
    "        x_decoded = self.decode_solution(x)\n",
    "        n_d, n_a = x_decoded[\"n_d\"], x_decoded[\"n_a\"]\n",
    "        n_steps, n_independent, n_shared = x_decoded[\"n_steps\"], x_decoded[\"n_independent\"], x_decoded[\"n_shared\"]\n",
    "        gamma, momentum = x_decoded[\"gamma\"], x_decoded[\"momentum\"]\n",
    "        tabnet_model = TabNetClassifier(n_d=n_d, n_a=n_a, n_steps=n_steps,\n",
    "                                        gamma=gamma, n_independent=n_independent, n_shared=n_shared,\n",
    "                                        momentum=momentum, verbose=0)\n",
    "        tabnet_model.loss_fn=FocalLoss(gamma=2.0, alpha=class_weights, reduction='mean')\n",
    "\n",
    "        # Fit the model\n",
    "        tabnet_model.fit(self.data[\"X_train\"], self.data[\"y_train\"],)\n",
    "        # Make the predictions\n",
    "        y_predict = tabnet_model.predict(self.data[\"X_test\"])\n",
    "        # Measure the performance\n",
    "        return metrics.accuracy_score(self.data[\"y_test\"], y_predict)\n",
    "\n",
    "\n",
    "my_bounds = [\n",
    "    FloatVar(lb=1.0, ub=2., name=\"gamma\"),\n",
    "    FloatVar(lb=0.01, ub=0.4, name=\"momentum\"),\n",
    "    IntegerVar(lb=8, ub=64, name=\"n_d\"),\n",
    "    IntegerVar(lb=8, ub=64, name=\"n_a\"),\n",
    "    IntegerVar(lb=3, ub=10, name=\"n_steps\"),\n",
    "    IntegerVar(lb=1, ub=5, name=\"n_independent\"),\n",
    "    IntegerVar(lb=1, ub=5, name=\"n_shared\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36caa0754ca5eed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:41:50.746828200Z",
     "start_time": "2024-05-28T10:26:56.956627Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mealpy.system_based import PSO\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Best weights from best epoch are automatically used!\")\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Detected call of `lr_scheduler.step()` before `optimizer.step()`\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "problem = TabNetOptimizedProblem(bounds=my_bounds, minmax=\"max\", data=data)\n",
    "model = PSO.OriginalPSO(epoch=10, pop_size=20,verbose=True)\n",
    "model.solve(problem)\n",
    "\n",
    "print(f\"Best agent: {model.g_best}\")\n",
    "print(f\"Best solution: {model.g_best.solution}\")\n",
    "print(f\"Best accuracy: {model.g_best.target.fitness}\")\n",
    "print(f\"Best parameters: {model.problem.decode_solution(model.g_best.solution)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27589dc70946ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
